# ğŸš€ LangChain.js Complete AI Application

A comprehensive Next.js application demonstrating all major LangChain.js capabilities with Google Gemini integration. This project showcases text generation, image analysis, speech processing, transcription, multimodal processing, and more.

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Tech Stack](#-tech-stack)
- [Setup Instructions](#-setup-instructions)
- [Project Structure](#-project-structure)
- [API Endpoints](#-api-endpoints)
- [Usage Examples](#-usage-examples)
- [LangChain.js vs Vercel AI SDK](#-langchainjs-vs-vercel-ai-sdk)
- [Contributing](#-contributing)

## âœ¨ Features

### ğŸ¯ Core AI Capabilities
- **Text Generation** - Basic chat and structured output with Gemini
- **Image Analysis** - Upload images for OCR, content analysis, and visual Q&A
- **Speech Processing** - Generate speech scripts and analyze speech patterns
- **Transcript Analysis** - Process audio transcripts and extract insights
- **Multimodal Processing** - Handle multiple content types simultaneously
- **Feature Comparison** - AI-powered comparison between LangChain.js and Vercel AI SDK

### ğŸ”§ Advanced Features
- **Streaming Support** - Real-time text and structured output streaming
- **Tool Calling** - Function calling and external tool integration
- **File Upload** - Support for image files (PNG, JPEG)
- **Schema Validation** - Zod-based structured output validation
- **Error Handling** - Comprehensive error handling and validation
- **Responsive UI** - Modern, mobile-friendly interface

## ğŸ› ï¸ Tech Stack

- **Framework**: Next.js 15 with App Router
- **AI Framework**: LangChain.js
- **AI Model**: Google Gemini 2.0 Flash
- **Styling**: Tailwind CSS
- **Validation**: Zod
- **Language**: TypeScript
- **Deployment**: Vercel-ready

## ğŸš€ Setup Instructions

### Prerequisites
- Node.js 18+ 
- npm or pnpm
- Google AI API key

### 1. Clone the Repository
```bash
git clone <your-repo-url>
cd langchainjs-examples
```

### 2. Install Dependencies
```bash
npm install
# or
pnpm install
```

### 3. Environment Setup
Create a `.env.local` file in the root directory:
```bash
GOOGLE_API_KEY=your_google_api_key_here
```

**Getting Google API Key:**
1. Go to [Google AI Studio](https://aistudio.google.com/)
2. Sign in with your Google account
3. Click "Get API Key" 
4. Create a new API key
5. Copy the key to your `.env.local` file

### 4. Run the Development Server
```bash
npm run dev
# or
pnpm dev
```

### 5. Open Your Browser
Navigate to `http://localhost:3000` to see the application.

## ğŸ“ Project Structure

```
langchainjs-examples/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                    # API routes
â”‚   â”‚   â”œâ”€â”€ text/route.ts       # Text generation API
â”‚   â”‚   â”œâ”€â”€ image/route.ts      # Image analysis API
â”‚   â”‚   â”œâ”€â”€ speech/route.ts     # Speech processing API
â”‚   â”‚   â””â”€â”€ transcription/route.ts # Transcript analysis API
â”‚   â”œâ”€â”€ simple-chat-llm/        # Basic text generation examples
â”‚   â”‚   â”œâ”€â”€ chat.ts
â”‚   â”‚   â”œâ”€â”€ structured-chat.ts
â”‚   â”‚   â”œâ”€â”€ schema-examples.ts
â”‚   â”‚   â””â”€â”€ prompt-reveal.ts
â”‚   â”œâ”€â”€ streaming/              # Streaming examples
â”‚   â”‚   â”œâ”€â”€ stream-text.ts
â”‚   â”‚   â””â”€â”€ stream-structured.ts
â”‚   â”œâ”€â”€ tool-calling/           # Tool calling examples
â”‚   â”‚   â”œâ”€â”€ basic-tools.ts
â”‚   â”‚   â””â”€â”€ advanced-tools.ts
â”‚   â”œâ”€â”€ image-generation/       # Image processing
â”‚   â”‚   â”œâ”€â”€ image-prompts.ts
â”‚   â”‚   â”œâ”€â”€ image-analysis.ts
â”‚   â”‚   â””â”€â”€ page.tsx           # UI for image analysis
â”‚   â”œâ”€â”€ speech/                 # Speech processing
â”‚   â”‚   â”œâ”€â”€ speech-processing.ts
â”‚   â”‚   â””â”€â”€ page.tsx           # UI for speech processing
â”‚   â”œâ”€â”€ transcription/          # Transcript processing
â”‚   â”‚   â”œâ”€â”€ transcript-processing.ts
â”‚   â”‚   â””â”€â”€ page.tsx           # UI for transcript analysis
â”‚   â”œâ”€â”€ multimodal/            # Multimodal processing
â”‚   â”‚   â”œâ”€â”€ content-analysis.ts
â”‚   â”‚   â””â”€â”€ page.tsx           # UI for multimodal processing
â”‚   â”œâ”€â”€ comparison/            # Feature comparison
â”‚   â”‚   â”œâ”€â”€ feature-comparison.ts
â”‚   â”‚   â””â”€â”€ page.tsx           # UI for comparison
â”‚   â”œâ”€â”€ page.tsx               # Main homepage
â”‚   â””â”€â”€ layout.tsx             # App layout
â”œâ”€â”€ public/                     # Static assets
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ tailwind.config.js
â””â”€â”€ README.md
```

## ğŸ”Œ API Endpoints

### Text Generation
- **POST** `/api/text`
- **Body**: `{ "prompt": "Your text prompt" }`
- **Response**: `{ "success": true, "content": "AI response" }`

### Image Analysis
- **POST** `/api/image`
- **Body**: FormData with `image` file and `prompt` text
- **Response**: `{ "success": true, "content": "Image analysis" }`

### Speech Processing
- **POST** `/api/speech`
- **Body**: `{ "text": "Text to process", "processingType": "speech_script" }`
- **Response**: `{ "success": true, "content": "Processed speech" }`

### Transcript Analysis
- **POST** `/api/transcription`
- **Body**: `{ "transcript": "Audio transcript", "analysisType": "summary" }`
- **Response**: `{ "success": true, "content": "Analysis result" }`

## ğŸ’¡ Usage Examples

### 1. Basic Text Generation
```typescript
const response = await fetch('/api/text', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ prompt: 'Explain quantum computing' })
});
const data = await response.json();
console.log(data.content);
```

### 2. Image Analysis
```typescript
const formData = new FormData();
formData.append('image', imageFile);
formData.append('prompt', 'What do you see in this image?');

const response = await fetch('/api/image', {
  method: 'POST',
  body: formData
});
const data = await response.json();
console.log(data.content);
```

### 3. Structured Output
```typescript
import { z } from "zod";

const schema = z.object({
  answer: z.string().describe("The main answer"),
  confidence: z.number().min(0).max(1)
});

const structuredModel = model.withStructuredOutput(schema);
const result = await structuredModel.invoke("What is AI?");
```

## âš–ï¸ LangChain.js vs Vercel AI SDK

| Feature | LangChain.js | Vercel AI SDK | Best For |
|---------|--------------|---------------|----------|
| **Text Generation** | `model.invoke()` | `generateText()` | LangChain: Complex workflows |
| **Structured Output** | `withStructuredOutput()` | `generateObject()` | LangChain: Advanced schemas |
| **Streaming** | `model.stream()` | `streamText()` | Both: Real-time apps |
| **Tool Calling** | `bindTools()` | Built-in | LangChain: Advanced tools |
| **State Management** | Built-in chains | None | LangChain: Complex workflows |
| **Multimodal** | Full support | Limited | LangChain: Image/audio |
| **React Components** | None | Built-in | Vercel: Quick UI |
| **Learning Curve** | Steeper | Gentle | Vercel: Simple apps |

### When to Choose Each:

**Choose LangChain.js if:**
- Building complex AI workflows
- Need advanced prompt engineering
- Want extensive tool integration
- Building enterprise applications
- Need multimodal capabilities

**Choose Vercel AI SDK if:**
- Building simple chat applications
- Need React components out of the box
- Want minimal setup
- Building Next.js applications
- Need quick prototyping

## ğŸ¯ Key Learnings

1. **LangChain.js is more powerful** but has a steeper learning curve
2. **Vercel AI SDK is simpler** but limited to basic text generation
3. **Both use the same underlying AI models** - the difference is in the framework
4. **LangChain.js excels at complex workflows** with state management and tool integration
5. **Vercel AI SDK excels at quick UI development** with built-in React components

## ğŸ”§ Development

### Running Examples
```bash
# Run specific examples
npx tsx app/simple-chat-llm/chat.ts
npx tsx app/streaming/stream-text.ts
npx tsx app/tool-calling/basic-tools.ts
```

### Building for Production
```bash
npm run build
npm start
```

## ğŸ“š Additional Resources

- [LangChain.js Documentation](https://js.langchain.com/)
- [Google AI Studio](https://aistudio.google.com/)
- [Next.js Documentation](https://nextjs.org/docs)
- [Tailwind CSS](https://tailwindcss.com/)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

**Built with â¤ï¸ using LangChain.js, Next.js, and Google Gemini**